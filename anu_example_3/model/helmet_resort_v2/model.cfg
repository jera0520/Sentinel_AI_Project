[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=64
subdivisions=1
width=192
height=192
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 2
exposure = 2.2
hue=.2

letter_box=1
blur=0

learning_rate=0.00065
burn_in=4000
max_batches = 500020
policy=steps
steps=400000,450000
scales=.1,.1

[convolutional]
batch_normalize=1
filters=32
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[route]
layers=-1
groups=2
group_id=1

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[route]
layers = -1,-2

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -6,-1

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[route]
layers=-1
groups=2
group_id=1

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[route]
layers = -1,-2

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -6,-1

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[route]
layers=-1
groups=2
group_id=1

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[route]
layers = -1,-2

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -6,-1

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

##################################

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=21
activation=linear



[yolo]
mask = 6,7,8
anchors =  53, 26,  58, 34,  74, 29,  80, 37,  66, 46, 102, 33,  80, 59, 105, 47, 120, 70
classes=2
num=9
jitter=.4
scale_x_y = 1.05
obj_normalizer=1.0
cls_normalizer=1.0
iou_thresh=0.2
iou_normalizer=0.03
iou_loss=ciou
ignore_thresh = .8
truth_thresh = 1
random=0
resize=0.8
nms_kind=diounms
beta_nms=0.6
max_delta=2
counters_per_class = 111510, 138908
max=1

[route]
layers = -4

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 23

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=21
activation=linear

[yolo]
mask = 3,4,5
anchors =  53, 26,  58, 34,  74, 29,  80, 37,  66, 46, 102, 33,  80, 59, 105, 47, 120, 70
classes=2
num=9
jitter=.4
scale_x_y = 1.05
obj_normalizer=1.0
cls_normalizer=1.0
iou_thresh=0.2
iou_normalizer=0.03
iou_loss=ciou
ignore_thresh = .8
truth_thresh = 1
random=0
resize=0.8
nms_kind=diounms
beta_nms=0.6
max_delta=2
counters_per_class = 111510, 138908
max=1

[route]
layers = -3

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 15

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=21
activation=linear

[yolo]
mask = 0,1,2
anchors =  53, 26,  58, 34,  74, 29,  80, 37,  66, 46, 102, 33,  80, 59, 105, 47, 120, 70
classes=2
num=9
jitter=.4
scale_x_y = 1.05
obj_normalizer=1.0
cls_normalizer=1.0
iou_thresh=0.2
iou_normalizer=0.03
iou_loss=ciou
ignore_thresh = .8
truth_thresh = 1
random=0
resize=0.8
nms_kind=diounms
beta_nms=0.6
max_delta=2
counters_per_class = 111510, 138908
max=1
