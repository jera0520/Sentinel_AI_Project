#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Slide 5: ë°ì´í„° ì¬ì •ì œ ì‹¤í–‰ ë° ê²°ê³¼ ì‹œê°í™”
"""
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from matplotlib.patches import FancyBboxPatch, Circle, Rectangle
import numpy as np

plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

# ============================================
# 1. ì„ ë³„/ì œì™¸ ê¸°ì¤€ ì‹œê°í™”
# ============================================
fig1, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
fig1.suptitle('Data Refinement: Selection & Exclusion Criteria', 
              fontsize=16, fontweight='bold')

# 1-1. ì„ ë³„ ê¸°ì¤€ (ì™¼ìª½)
ax1.axis('off')
ax1.set_xlim(0, 10)
ax1.set_ylim(0, 10)

# ì œëª©
ax1.text(5, 9.5, 'SELECTION CRITERIA', 
         ha='center', fontsize=14, fontweight='bold', 
         bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgreen', alpha=0.8))

# ê¸°ì¤€ë“¤
criteria_include = [
    ('1. Clear Object Visibility', 'Objects (helmet/person) clearly visible', 'âœ“'),
    ('2. Person Included', 'Full person in frame', 'âœ“'),
    ('3. Clear Status', 'Helmet wearing status unambiguous', 'âœ“'),
    ('4. Moderate Background', 'Realistic construction site complexity', 'âœ“'),
]

y_pos = 8
for title, desc, check in criteria_include:
    # ì²´í¬ë§ˆí¬
    ax1.text(0.5, y_pos, check, fontsize=20, color='green', 
             fontweight='bold', ha='center')
    # ì œëª©
    ax1.text(1.5, y_pos, title, fontsize=11, fontweight='bold', va='center')
    # ì„¤ëª…
    ax1.text(1.5, y_pos-0.4, desc, fontsize=9, color='gray', va='center')
    
    # êµ¬ë¶„ì„ 
    if y_pos > 2:
        ax1.plot([0.3, 9.7], [y_pos-0.9, y_pos-0.9], 'k-', alpha=0.2)
    
    y_pos -= 2

ax1.text(5, 0.5, 'Target: ~200 images per category', 
         ha='center', fontsize=10, style='italic',
         bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.5))

# 1-2. ì œì™¸ ê¸°ì¤€ (ì˜¤ë¥¸ìª½)
ax2.axis('off')
ax2.set_xlim(0, 10)
ax2.set_ylim(0, 10)

# ì œëª©
ax2.text(5, 9.5, 'EXCLUSION CRITERIA', 
         ha='center', fontsize=14, fontweight='bold',
         bbox=dict(boxstyle='round,pad=0.5', facecolor='lightcoral', alpha=0.8))

# ê¸°ì¤€ë“¤
criteria_exclude = [
    ('1. Blurry/Unclear', 'Poor image quality or focus', 'âœ—'),
    ('2. Occluded Objects', 'Person/helmet heavily obscured', 'âœ—'),
    ('3. Too Small Objects', 'Objects < 50px (too small)', 'âœ—'),
    ('4. Ambiguous Status', 'Helmet status unclear', 'âœ—'),
    ('5. Extreme Background', 'Too complex or too simple', 'âœ—'),
]

y_pos = 8.5
for title, desc, check in criteria_exclude:
    # Xë§ˆí¬
    ax2.text(0.5, y_pos, check, fontsize=20, color='red', 
             fontweight='bold', ha='center')
    # ì œëª©
    ax2.text(1.5, y_pos, title, fontsize=11, fontweight='bold', va='center')
    # ì„¤ëª…
    ax2.text(1.5, y_pos-0.4, desc, fontsize=9, color='gray', va='center')
    
    # êµ¬ë¶„ì„ 
    if y_pos > 2:
        ax2.plot([0.3, 9.7], [y_pos-0.9, y_pos-0.9], 'k-', alpha=0.2)
    
    y_pos -= 1.6

ax2.text(5, 0.5, 'Excluded: ~22,899 images', 
         ha='center', fontsize=10, style='italic',
         bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgray', alpha=0.5))

plt.tight_layout()
plt.savefig('slide5_selection_criteria.png', dpi=300, bbox_inches='tight')
print("âœ… ì„ ë³„/ì œì™¸ ê¸°ì¤€ ì €ì¥: slide5_selection_criteria.png")

# ============================================
# 2. ì‘ì—… í”„ë¡œì„¸ìŠ¤ í”Œë¡œìš°
# ============================================
fig2, ax = plt.subplots(figsize=(12, 8))
ax.set_xlim(0, 10)
ax.set_ylim(0, 10)
ax.axis('off')

fig2.suptitle('Data Refinement Workflow', fontsize=16, fontweight='bold')

# ë‹¨ê³„ë³„ ë°•ìŠ¤
steps = [
    {
        'y': 8.5, 
        'title': 'Step 1: Manual Selection',
        'desc': 'â€¢ Review 23,899 images one by one\nâ€¢ Select based on criteria\nâ€¢ Ensure diversity',
        'color': '#FFE5CC'
    },
    {
        'y': 6.5,
        'title': 'Step 2: Category Distribution',
        'desc': 'â€¢ Class: 200 each (helmet/no helmet/fallen)\nâ€¢ Environment: 200 each (indoor/outdoor)\nâ€¢ Background: 200 each (clean/complex)',
        'color': '#E5CCFF'
    },
    {
        'y': 4.5,
        'title': 'Step 3: YOLO Mark Validation',
        'desc': 'â€¢ Load selected images\nâ€¢ Verify bounding boxes\nâ€¢ Correct label errors',
        'color': '#CCF5FF'
    },
    {
        'y': 2.5,
        'title': 'Step 4: Final Quality Check',
        'desc': 'â€¢ Confirm balance\nâ€¢ Check image quality\nâ€¢ Validate labels',
        'color': '#CCFFCC'
    },
]

for i, step in enumerate(steps):
    # ë°•ìŠ¤
    box = FancyBboxPatch((1, step['y']-0.6), 8, 1.2, 
                         boxstyle="round,pad=0.1", 
                         facecolor=step['color'], 
                         edgecolor='black', linewidth=2)
    ax.add_patch(box)
    
    # ì œëª©
    ax.text(5, step['y']+0.3, step['title'], 
            ha='center', fontsize=12, fontweight='bold')
    
    # ì„¤ëª…
    ax.text(5, step['y']-0.2, step['desc'], 
            ha='center', fontsize=9, va='top')
    
    # í™”ì‚´í‘œ (ë§ˆì§€ë§‰ ì œì™¸)
    if i < len(steps) - 1:
        ax.annotate('', xy=(5, step['y']-0.7), xytext=(5, step['y']-1.2),
                   arrowprops=dict(arrowstyle='->', lw=3, color='black'))

# ê²°ê³¼ ë°•ìŠ¤
result_box = FancyBboxPatch((2, 0.3), 6, 1, 
                           boxstyle="round,pad=0.1",
                           facecolor='#FFD700', 
                           edgecolor='red', linewidth=3)
ax.add_patch(result_box)
ax.text(5, 0.8, 'Result: ~1,000 High-Quality Balanced Images', 
        ha='center', fontsize=12, fontweight='bold')

plt.tight_layout()
plt.savefig('slide5_workflow.png', dpi=300, bbox_inches='tight')
print("âœ… ì‘ì—… í”„ë¡œì„¸ìŠ¤ ì €ì¥: slide5_workflow.png")

# ============================================
# 3. Before/After ê°•ì¡° ë¹„êµ
# ============================================
fig3, ax = plt.subplots(figsize=(14, 8))
ax.set_xlim(0, 10)
ax.set_ylim(0, 10)
ax.axis('off')

fig3.suptitle('Data Refinement: Before vs After Comparison', 
              fontsize=16, fontweight='bold')

# Before (ì™¼ìª½)
before_box = FancyBboxPatch((0.5, 3), 4, 5.5,
                           boxstyle="round,pad=0.2",
                           facecolor='#FFCCCC', alpha=0.3,
                           edgecolor='red', linewidth=3)
ax.add_patch(before_box)

ax.text(2.5, 8.2, 'BEFORE', ha='center', fontsize=16, fontweight='bold', color='red')
ax.text(2.5, 7.7, '(Initial Data)', ha='center', fontsize=10, style='italic')

before_data = [
    ('Total Images:', '23,899'),
    ('Class Balance:', 'Imbalanced âœ—'),
    ('  - Helmet:', '18,000 (75%)'),
    ('  - No Helmet:', '2,000 (8%)'),
    ('  - Fallen:', '3,899 (17%)'),
    ('', ''),
    ('Environment:', 'Imbalanced âœ—'),
    ('  - Indoor:', '20,000 (84%)'),
    ('  - Outdoor:', '3,899 (16%)'),
    ('', ''),
    ('Quality:', 'Mixed'),
    ('mAP:', '45% âœ—'),
]

y = 7
for label, value in before_data:
    if label:
        ax.text(0.8, y, label, fontsize=10, fontweight='bold' if ':' in label else 'normal')
        ax.text(4, y, value, fontsize=10, ha='right',
               color='red' if 'âœ—' in value else 'black')
    y -= 0.35

# í™”ì‚´í‘œ
ax.annotate('REFINEMENT\nPROCESS', xy=(5.5, 5.5), xytext=(5.5, 6.5),
           ha='center', fontsize=14, fontweight='bold', color='green',
           arrowprops=dict(arrowstyle='->', lw=4, color='green'))

# After (ì˜¤ë¥¸ìª½)
after_box = FancyBboxPatch((5.5, 3), 4, 5.5,
                          boxstyle="round,pad=0.2",
                          facecolor='#CCFFCC', alpha=0.3,
                          edgecolor='green', linewidth=3)
ax.add_patch(after_box)

ax.text(7.5, 8.2, 'AFTER', ha='center', fontsize=16, fontweight='bold', color='green')
ax.text(7.5, 7.7, '(Refined Data)', ha='center', fontsize=10, style='italic')

after_data = [
    ('Total Images:', '~1,000'),
    ('Class Balance:', 'Balanced âœ“'),
    ('  - Helmet:', '200 (33%)'),
    ('  - No Helmet:', '200 (33%)'),
    ('  - Fallen:', '200 (33%)'),
    ('', ''),
    ('Environment:', 'Balanced âœ“'),
    ('  - Indoor:', '200 (50%)'),
    ('  - Outdoor:', '200 (50%)'),
    ('', ''),
    ('Quality:', 'High âœ“'),
    ('mAP:', '87% âœ“'),
]

y = 7
for label, value in after_data:
    if label:
        ax.text(5.8, y, label, fontsize=10, fontweight='bold' if ':' in label else 'normal')
        ax.text(9, y, value, fontsize=10, ha='right',
               color='green' if 'âœ“' in value else 'black',
               fontweight='bold' if 'âœ“' in value or 'mAP' in label else 'normal')
    y -= 0.35

# í•µì‹¬ ë©”ì‹œì§€
message_box = FancyBboxPatch((1, 0.5), 8, 1.8,
                            boxstyle="round,pad=0.2",
                            facecolor='#FFD700', alpha=0.5,
                            edgecolor='blue', linewidth=3)
ax.add_patch(message_box)

ax.text(5, 1.9, 'ğŸ’¡ KEY INSIGHT', ha='center', fontsize=14, fontweight='bold', color='blue')
ax.text(5, 1.4, '"Quality & Balance > Quantity"', 
        ha='center', fontsize=16, fontweight='bold', style='italic')
ax.text(5, 0.9, 'Model performance improved from 45% to 87% mAP (+42%p)', 
        ha='center', fontsize=11, color='green', fontweight='bold')

plt.tight_layout()
plt.savefig('slide5_before_after_comparison.png', dpi=300, bbox_inches='tight')
print("âœ… Before/After ë¹„êµ ì €ì¥: slide5_before_after_comparison.png")

# ============================================
# 4. ìµœì¢… ë°ì´í„°ì…‹ êµ¬ì„± (íŒŒì´ ì°¨íŠ¸)
# ============================================
fig4, axes = plt.subplots(1, 3, figsize=(15, 5))
fig4.suptitle('Final Dataset Composition (~1,000 images)', 
              fontsize=16, fontweight='bold')

# 4-1. í´ë˜ìŠ¤ ë¶„í¬
ax1 = axes[0]
classes = ['Helmet\n(200)', 'No Helmet\n(200)', 'Fallen\n(200)']
sizes = [200, 200, 200]
colors1 = ['#66b3ff', '#ff9999', '#99ff99']

wedges1, texts1, autotexts1 = ax1.pie(sizes, labels=classes, colors=colors1,
                                        autopct='33.3%%', startangle=90,
                                        textprops={'fontsize': 11, 'fontweight': 'bold'})
ax1.set_title('Class Distribution\n(Balanced âœ“)', fontsize=12, fontweight='bold', color='green')

# 4-2. í™˜ê²½ ë¶„í¬
ax2 = axes[1]
envs = ['Indoor\n(200)', 'Outdoor\n(200)']
sizes2 = [200, 200]
colors2 = ['#ffcc99', '#c2f0c2']

wedges2, texts2, autotexts2 = ax2.pie(sizes2, labels=envs, colors=colors2,
                                        autopct='50%%', startangle=90,
                                        textprops={'fontsize': 11, 'fontweight': 'bold'})
ax2.set_title('Environment Distribution\n(Balanced âœ“)', fontsize=12, fontweight='bold', color='green')

# 4-3. ë°°ê²½ ë³µì¡ë„
ax3 = axes[2]
backgrounds = ['Clean\nBackground\n(200)', 'Complex\nBackground\n(200)']
sizes3 = [200, 200]
colors3 = ['#ff9999', '#99ccff']

wedges3, texts3, autotexts3 = ax3.pie(sizes3, labels=backgrounds, colors=colors3,
                                        autopct='50%%', startangle=90,
                                        textprops={'fontsize': 11, 'fontweight': 'bold'})
ax3.set_title('Background Complexity\n(Balanced âœ“)', fontsize=12, fontweight='bold', color='green')

plt.tight_layout()
plt.savefig('slide5_final_dataset.png', dpi=300, bbox_inches='tight')
print("âœ… ìµœì¢… ë°ì´í„°ì…‹ êµ¬ì„± ì €ì¥: slide5_final_dataset.png")

# ============================================
# 5. í•µì‹¬ ë©”ì‹œì§€ ê°•ì¡°
# ============================================
fig5, ax = plt.subplots(figsize=(12, 6))
ax.set_xlim(0, 10)
ax.set_ylim(0, 10)
ax.axis('off')

# ë°°ê²½ ê·¸ë¼ë°ì´ì…˜ íš¨ê³¼ (ë°•ìŠ¤ë“¤ë¡œ)
for i in range(10):
    alpha = 0.1 + (i * 0.05)
    rect = Rectangle((0, i), 10, 1, facecolor='lightblue', alpha=alpha)
    ax.add_patch(rect)

# ë©”ì¸ ë©”ì‹œì§€
ax.text(5, 7.5, 'ğŸ’¡ KEY MESSAGE', 
        ha='center', fontsize=20, fontweight='bold', color='darkblue')

# í•µì‹¬ ë¬¸êµ¬
main_msg = '"Quality & Balance"\n>\n"Quantity"'
ax.text(5, 5, main_msg, 
        ha='center', va='center', fontsize=32, fontweight='bold',
        bbox=dict(boxstyle='round,pad=1', facecolor='gold', 
                 edgecolor='red', linewidth=4, alpha=0.8))

# ìˆ˜ì¹˜ ë¹„êµ
ax.text(5, 2.5, '23,899 images (imbalanced) â†’ 1,000 images (balanced)', 
        ha='center', fontsize=14, fontweight='bold')
ax.text(5, 1.8, 'Result: mAP 45% â†’ 87% (+42%p improvement)', 
        ha='center', fontsize=16, fontweight='bold', color='green')

# ê²°ë¡ 
ax.text(5, 0.8, 'Data quality and balance are MORE important than quantity for model performance', 
        ha='center', fontsize=12, style='italic',
        bbox=dict(boxstyle='round,pad=0.5', facecolor='lightyellow', alpha=0.7))

plt.tight_layout()
plt.savefig('slide5_key_message.png', dpi=300, bbox_inches='tight')
print("âœ… í•µì‹¬ ë©”ì‹œì§€ ì €ì¥: slide5_key_message.png")

print("\n" + "="*60)
print("Slide 5 ì‹œê° ìë£Œ ìƒì„± ì™„ë£Œ!")
print("="*60)
print("\nìƒì„±ëœ íŒŒì¼:")
print("1. slide5_selection_criteria.png - ì„ ë³„/ì œì™¸ ê¸°ì¤€")
print("2. slide5_workflow.png - ì‘ì—… í”„ë¡œì„¸ìŠ¤")
print("3. slide5_before_after_comparison.png - Before/After ë¹„êµ (ê°•ì¡°)")
print("4. slide5_final_dataset.png - ìµœì¢… ë°ì´í„°ì…‹ êµ¬ì„±")
print("5. slide5_key_message.png - í•µì‹¬ ë©”ì‹œì§€")
print("="*60)

